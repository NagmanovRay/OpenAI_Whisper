# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hETXpqhaYGDK0QgOFjsXPazgKowmi3fr

***OpenAI Whisper***

In this project I will use OpenAI Whisper to transcribe data from Fed speech video and compare market market data during the time speech was live broadcasted. In order to analyze market reaction to specific words that Fed chair J.Powell says during the press conference.

First we need to download OpenAI Whisper Python package using pip.
"""

!pip install git+https://github.com/openai/whisper.git -q

"""We'll also make sure we have a GPU available in Google Colab. If you don't have a GPU, go to Runtime -> Change Runtime Type -> Hardware Accelator and select GPU. I have Colab Pro so I get access to Premium GPU's. Run the command below to show which GPU is being used in the current runtime:"""

!nvidia-sml-

"""Whisper transcribes audio speech to text. To see this in action, we'll need some audio to operate on. We'll extract some audio from a YouTube video using the pytube Python package. let's install it with pip.


"""

!pip install pytube -q

"""Now we can import Whisper, and YouTube from pytube."""

import whisper
from pytube import YouTube

"""OpenAI Whisper has a variety of model of different sizes. The larger the model the more accurate output is, however for this project base model will be sufficient."""

model = whisper.load_model('base')

"""We'll now instantiate a "YouTube" object by passing in the video URL. This will allow us to retrieve metadata and stream info about the specified YouTube URL."""

youtube_video_url = "https://www.youtube.com/watch?v=NT2H9iyd-ms"
youtube_video = YouTube(youtube_video_url)

"""Now that we have pytube object, let's explore some of it's attributes."""

youtube_video.title

"""In order to see other metadata from youtube video you may use dir(youtube_video)

We can get a list of video and audio streams of varying quality. For this project we only need audio files.
"""

youtube_video.streams

for stream in youtube_video.streams:
  print(stream)

"""Lets filter and get rid of video streams, and leave only audio files"""

streams = youtube_video.streams.filter(only_audio=True)
streams

"""For this project we do not need highest quality audio, so we can choose first stream."""

stream = streams.first()
stream

"""OK, now we have a single stream that we will use. Let's download the stream as fed_meeting.mp4. You should see the file appear in the filesystem browser on the side panel of Colab. Click the refresh button if you don't see it after a while."""

stream.download(filename='fed_meeting.mp4')

"""We can do some additional processing on the audio file should we choose. I want to ignore any additional sound and speech after Jerome Powell speaks. So we'll use ffmpeg to do this. The command will start the audio file at the 375 second mark where he starts with good afternoon, continue for 2715 seconds, and chop off the rest of the audio. The result will be saved in a new file called fed_meeting_trimmed.mp4."""

!ffmpeg -ss 378 -i fed_meeting.mp4 -t 2715 fed_meeting_trimmed.mp4

"""It is possible to embed an audio player into Google Colab, but will not do this for now since I have seen the runtime get disconnected on large audio files. If you want a copy of the resulting audio, you can download it locally using the Colab the file browser.

Transcribing itself may take a while depending on your hardware. Next line of code will use datetime to get the duration of the transcription process. I have tested different combinations of CPU/GPU and models to see the difference in time it takes different models to accomplish the same task.
"""

import datetime
# save the timestamps before transcription
t1 = datetime.datetime.now()
print(f"started at {t1}")

# do the transcription
output = model.transcribe('fed_meeting_trimmed.mp4')

#show time elapsed after transcription is complete.
t2 = datetime.datetime.now()
print(f"ended at {t2}")
print(f'time elapsed: {t2 - t1}')

"""We can get output, that provides a lot of data. Such as text, word tokens and etc,"""

output

"""Now we can get only text"""

output['text']

"""Let's loop through and get all the segments

"""

for segment in output['segments']:
  print(segment)
  second = int(segment['start'])
  second = second - (second % 5)
  print(second)

"""Ok now we have successfully transcibe the audio from the YouTube video by using OpenAI Whisper. There are many implementations of this, however for this project I am going to compare Speech Data with Price Action during the live broadcast of the given speech.

***Combining Speech Data with Price Data***

I will use external data from Interactive Broker (a file named spy.csv), a code and file for that can be found in the same Github repository
"""

import pandas as pd

spy = pd.read_csv("spy.csv")

spy

"""Since we already have the segments of the speech and their start and end times in seconds, we can add a new column containing the text that was spoken during each 5 second bar."""

for segment in output['segments']:
   second = int(segment['start'])
   second = second - (second % 5)
   spy.loc[second / 5, 'text'] = segment['text']

spy

"""Let's also create a new column called *percent* that stores the percent the
price moved during the 5 second period.
"""

spy['percent'] = ((spy['close'] - spy['open']) / spy['open']) * 100
spy

"""Lets filter out bars where price moved significantly and see what part of the speech coorelates to that. For example anybar that moved down more than 0.2%"""

big_downmoves = spy[spy.percent < -0.15]
big_downmoves

"""Lets use simple mplfinance charts to visualize the bar chart."""

!pip install mplfinance -q
import mplfinance as mpf

df = spy
df.index = pd.DatetimeIndex(df['date'])

mpf.plot(df['2022-11-02 14:36':'2022-11-02 14:39'],type='candle')

spy[50:70]['text']

"""***Conclusion***

To sum it all up,in this project we have used OpenAI Whisper to transcribe fed speech from a YouTube video. After that we compared and visualized Price Data during the speech in order to identify what part of the speech may have caused market to react significantly.
"""